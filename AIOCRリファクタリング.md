# **AI-OCRリファクタリング計画書：次世代モデル対応版**

## **1\. プロジェクト目標**

現在のAIOCRシステムのコアアーキテクチャを強化し、GPT-5のような次世代モデルの能力を最大限に引き出すための処理パイプラインを構築する。具体的には、以下の3点を実現する。

1. **無駄な処理の削減**: OCR処理の前に「品質ゲート」を設け、低品質な画像を早期に除外する。  
2. **データ特性に応じた処理の分岐**: 帳票の項目特性（固定長か自由記述か）に応じて、最適なAIモデルと処理フローを適用する。  
3. **客観的な信頼度評価**: 複数の指標を組み合わせた「複合信頼度スコア」を導入し、人間による確認が必要な項目をより正確に特定する。

## **2\. AIモデルの柔軟な切り替え設計**

将来のモデル（例: GPT-5-mini）への対応を容易にするため、以下の設計を導入する。

* **src/core/ocr\_bridge.py**:  
  * GPT5MiniVisionOCR のような新しいモデルクラスを追加するだけで、新しいエンジンをシステムに組み込めるようにする。  
* **src/app/pages/1\_Main\_OCR.py**:  
  * サイドバーのOCRエンジン選択 st.selectbox の選択肢に、ocr\_bridge.py に追加されたモデルが動的に表示されるようにする。

## **3\. 開発フェーズ計画**

### **フェーズ 0: 基盤リファクタリングと品質ゲートの導入**

**目標:** OCR処理の入り口に「品質ゲート」を設け、低品質な画像を早期に除外することで、後続処理の無駄をなくし、システム全体の効率と安定性を向上させる。

**タスク詳細:**

1. **src/core/quality\_gate.py の新規作成:**  
   * 画像品質を評価するための新しいモジュールを作成する。  
   * 以下の関数を実装する。  
     * check\_sharpness(image: np.ndarray, threshold: float \= 100.0) \-\> bool: 画像の鮮明度を評価する（例: cv2.Laplacian の分散値を計算し、閾値と比較）。  
     * is\_quality\_sufficient(image: np.ndarray) \-\> tuple\[bool, str\]: 上記のチェックを統括し、品質が十分かどうかを判定する。戻り値は (合否フラグ, 理由テキスト) とする（例: (False, "画像が不鮮明です")）。  
2. **src/core/ocr\_agent.py の改修:**  
   * OcrAgent.process\_document メソッドの冒頭で、quality\_gate.is\_quality\_sufficient を呼び出す。  
   * 品質チェックに失敗した場合、OCR処理（OCRProcessorの呼び出し）をスキップする。  
   * 代わりに、db\_manager を使って結果をDBに保存する。この際、status カラムに "QualityCheckFailed" というステータスと、失敗理由を記録する。final\_text は空で構わない。

**テスト:**

* tests/test\_quality\_gate.py を新規作成し、意図的に作成した「鮮明な画像」と「ぼやけた画像」を is\_quality\_sufficient が正しく判定することを確認する。  
* tests/test\_ocr\_agent.py に、低品質画像を渡した場合にOCR処理がスキップされ、DBに正しいステータスが記録されることを検証するテストを追加する。

### **フェーズ 1: 「フィールドタイプ」の導入と処理分岐の準備**

**目標:** テンプレートに「固定フィールド」と「定性フィールド」の概念を導入し、将来的に処理フローを分岐させるための基礎を築く。

**タスク詳細:**

1. **src/app/pages/0\_Template\_Editor.py のUI改修:**  
   * 各ROI（読み取り領域）の設定エリアに、st.selectbox を使って「フィールドタイプ」を選択するUIを追加する。  
   * 選択肢は「**固定フィールド**（例: 日付、金額）」「**定性フィールド**（例: 備考、所見）」とし、デフォルトは「固定フィールド」とする。  
2. **src/core/template\_manager.py の機能拡張:**  
   * テンプレートのJSONファイルにおいて、各ROIの定義に field\_type というキーで選択されたタイプが保存されるように save メソッドを改修する。  
3. **src/core/ocr\_processor.py の構造リファクタリング:**  
   * OCRProcessor.\_process\_file メソッドのロジックをリファクタリングし、ROI定義から field\_type を読み取り、それに応じて内部の処理メソッドを呼び分ける構造にする。  
     * \_process\_fixed\_field(self, image, roi\_def)  
     * \_process\_qualitative\_field(self, image, roi\_def)  
   * **このフェーズでは、両メソッドの中身は既存のOCR処理ロジックのままで構わない。** 目的は、将来の機能拡張に備えて分岐構造を整備すること。

**テスト:**

* tests/test\_template\_manager.py を更新し、field\_type が正しく保存・読み込みできることを確認する。  
* tests/test\_ocr\_processor.py を更新し、field\_type が異なるROIを持つテストテンプレートを作成し、\_process\_file を呼び出した際に、適切な内部メソッドが呼び出されることを unittest.mock.patch を使って検証する。

### **フェーズ 2: フィールドタイプ別 特化処理の実装**

**目標:** 固定フィールドと定性フィールドに対して、それぞれに最適化されたOCR処理ロジックを実装する。

**タスク詳細:**

1. **src/core/ocr\_processor.py の \_process\_fixed\_field を改修:**  
   * **ルールベースを主軸**とする。メインのOCRエンジンでテキストを抽出後、テンプレートの validation\_rule で即座に検証する。  
   * **検証に失敗した場合に限り**、補助的な高速モデルを**特定の正規化プロンプト**（例: 「このテキストを7桁の数字に修正してください」）で呼び出し、再度検証する。  
   * needs\_human フラグは、主にルール検証の最終結果に基づいて設定する。  
2. **src/core/ocr\_processor.py の \_process\_qualitative\_field を改修:**  
   * **LLMの読解能力を主軸**とする。既存のダブルチェックロジック（miniとnanoの結果を比較）を維持、または強化する。  
   * 信頼度は、2つのモデルのテキストの一致度（文字列の類似度など）を重視して決定する。

**テスト:**

* tests/test\_ocr\_processor.py に新しいテストシナリオを追加する。  
  * **固定フィールド:** 初期OCR結果がルール違反となるケースを作成し、この場合に補助モデルへの「正規化APIコール」が1回だけ行われることをモックで確認する。  
  * **定性フィールド:** ダブルチェックロジックが維持され、2つのOCRエンジンが呼び出されることを確認する。

### **フェーズ 3: 複合信頼度スコアと高度なレビューキューイング**

**目標:** 従来の曖昧な信頼度評価を刷新し、複数の客観的指標に基づいた**複合信頼度スコア**を導入する。

**タスク詳細:**

1. **src/core/db\_manager.py のスキーマ変更:**  
   * ocr\_results テーブルを修正し、confidence\_score を composite\_score に改名する。  
   * 評価の内訳を保存するため、score\_ocr (AIの自己評価)、score\_rule (ルール適合度)、score\_agreement (モデル間一致度) などの REAL 型カラムを新たに追加する。  
2. **src/core/postprocess.py の機能追加:**  
   * calculate\_composite\_score(...) 関数を新規作成し、各スコアを重み付けして最終スコアを算出する。  
3. **src/core/ocr\_processor.py のスコア計算ロジック実装:**  
   * \_process\_fixed\_field と \_process\_qualitative\_field の中で、それぞれの処理結果に応じて score\_ocr, score\_rule などを計算する。  
   * 最後に calculate\_composite\_score を呼び出し、composite\_score を算出する。  
   * needs\_human フラグは、この composite\_score が閾値を下回るかどうかで決定する。  
   * 算出した各スコアをDBに保存する。

**テスト:**

* tests/test\_db\_manager.py を新しいスキーマに合わせて更新する。  
* tests/test\_ocr\_processor.py に、各シナリオで composite\_score が期待通りに計算されることを検証するテストを追加する。

### **最終統合テスト**

**目標:** 全てのフェーズ変更を統合したシステムが、エンドツーエンドで正常に動作することを確認する。

**手順:**

1. **テストデータの準備:** 品質が良い画像と悪い画像、固定/定性フィールドが混在する新しいテスト用テンプレートを用意する。  
2. **実行:** setup\_and\_run.bat を実行してアプリケーションを起動。  
3. **Template Editor の検証:** フィールドタイプ（固定/定性）の選択UIが正しく機能し、保存されることを確認。  
4. **Main OCR の検証:** 品質ゲートによって低品質画像が処理開始前に弾かれることを確認。  
5. **Review 画面の検証:** 複合スコアが低い項目のみがレビュー対象としてリストアップされることを確認。  
6. **データベースの直接確認:** SQLiteのDBファイルを開き、ocr\_results テーブルに新しいスコアカラムが正しく記録されていることを確認する。