# **AIOCR開発プロジェクト 逐次実行型タスク指示書 (Streamlit版)**

### **1\. はじめに**

このドキュメントは、AIOCR（光学的文字認識）システムを段階的に開発するための、AIアシスタント向けタスク指示書です。各フェーズは具体的でテスト可能な小さな単位に分割されています。**GUIフレームワークとしてStreamlitを使用します。**

**開発を進める上での絶対的なルール:**

1. **フェーズの厳守**: 必ずフェーズ0から順番に、1つずつタスクを実行してください。複数のフェーズを同時に進めてはいけません。  
2. **テストの徹底**: 各フェーズの最後には、指定されたテストをすべて実行してください。すべてのテストが成功した場合のみ、次のフェーズに進むことができます。  
3. **GitHubルールの遵守**: 後述するGitHubの運用ルールに厳密に従ってください。これにより、チームでの共同作業を円滑にし、エラーの発生を防ぎます。

### **2\. GitHub 運用ルール (最重要)**

| ルール項目 | 内容 | 具体例 |
| :---- | :---- | :---- |
| **ブランチ戦略** | mainブランチは常に本番稼働可能な状態を保ちます。開発はdevelopブランチから、feature/phase-X-説明という名前のブランチを作成して行います。 | git checkout develop\<br\>git pull\<br\>git checkout \-b feature/phase-1-preprocessing |
| **コミットメッセージ** | コミットメッセージは[Conventional Commits](https://www.conventionalcommits.org/ja/v1.0.0/)の規約に従います。変更の種類 (feat, fix, docs等) と影響範囲を明確に記述してください。 | feat(preprocess): add skew correction function\<br\>fix(ui): fix file uploader bug\<br\>docs(readme): update setup instructions |
| **プルリクエスト (PR)** | 1つのフェーズが完了したら、feature/...ブランチからdevelopブランチへのプルリクエストを作成します。PRには、**変更内容、実行したテスト、結果**を必ず記述してください。 | **PRタイトル:** feat: Implement Phase 1 Preprocessing\<br\>**本文:** \<br\>- 画像の傾き補正とROI切り出し機能を実装。\<br\>- pytestによる単体テストをすべてパス。 |

## **開発フェーズ**

### **フェーズ 0: Streamlitプロジェクトのセットアップ**

**目標:** プロジェクトの土台を作り、Streamlitアプリが最低限動作する状態にする。

**タスク:**

1. Pythonプロジェクトを初期化し、pyproject.tomlを作成します。  
2. 使用するライブラリを定義します: streamlit, pandas, pydantic, opencv-python, python-dotenv, pyyaml。  
3. 以下のディレクトリ構造を作成します。これは最初の仕様書に準拠しています。  
   .  
   ├── src/  
   │   └── app/  
   │       ├── \_\_init\_\_.py  
   │       ├── main.py          \# Streamlitアプリ本体  
   │       ├── core/  
   │       │   └── config.py  
   │       └── pages/           \# Streamlitのマルチページ用  
   │           └── 1\_Review.py  
   │           └── 2\_Dashboard.py  
   ├── tests/  
   ├── workspace/  
   │   ├── logs/  
   │   └── templates/  
   └── .env

4. src/app/main.pyにStreamlitの雛形を作成します。「AIOCR処理実行」というタイトルと、ファイルをアップロードするためのst.file\_uploaderを設置します。

**テスト:**

1. streamlit run src/app/main.pyコマンドでアプリを起動できることを確認します。  
2. ブラウザにタイトルとファイルアップロードウィジェットが表示されることを確認します。

**完了報告:** feature/phase-0-setupブランチからdevelopへプルリクエストを作成してください。

### **フェーズ 1: 画像の前処理とROI切り出し**

**目標:** アップロードされた画像を処理し、定義された領域を切り出せるようにする。

**タスク:**

1. src/app/preprocess.pyモジュールを作成します。OpenCVを使い、傾き補正、二値化、ROI切り出し関数を実装します。  
2. ファイルがアップロードされたら、workspace/DOC\_YYYYMMDD\_HHMMSS/という形式でユニークな作業ディレクトリを作成します。  
3. アップロードされたrois.yaml（または後述のテンプレート）を読み込み、切り出した画像を作業ディレクトリ/crops/内にP1\_field\_a.pngのように保存します。  
4. 処理が完了したら、Streamlitの画面に「処理完了」と表示し、作成された作業ディレクトリのパスを表示します。

**テスト:**

1. 傾いたサンプル画像とrois.yamlをアップロードします。  
2. workspace/内に新しいDOC\_...ディレクトリが作成され、その中のcrops/に正しく切り出された画像が保存されていることを確認します。  
3. tests/にpreprocess.pyの単体テストを作成し、pytestで成功することを確認します。

**完了報告:** feature/phase-1-preprocessingブランチからdevelopへプルリクエストを作成してください。

### **フェーズ 2: OCRモデルブリッジとダミーOCR処理**

**目標:** 実際のAIモデルを組み込むための「橋渡し」部分を作り、全体の流れを完成させる。

**タスク:**

1. src/app/ocr\_bridge.pyとsrc/app/ocr\_processor.pyを作成します。（指示書のロジックは流用）  
2. DummyOCRを使い、各切り出し画像に対してダミーのOCR処理を実行します。  
3. 結果を作業ディレクトリ/extract.jsonに保存します。  
4. Streamlitの画面に、extract.jsonの内容をst.json()を使って表示します。

**テスト:**

1. フェーズ1のテストを再度実行します。  
2. 作業ディレクトリ/にextract.jsonが生成され、その内容がStreamlitの画面に正しく表示されることを確認します。

**完了報告:** feature/phase-2-ocr-bridgeブランチからdevelopへプルリクエストを作成してください。

### **フェーズ 3: 実際のOCRモデルの統合**

**目標:** ダミーではなく、実際のAIモデルを使って文字認識を行う。

**タスク:**

1. ocr\_bridge.pyにGPT4oMiniVisionOCR(BaseOCR)アダプタを実装します。（指示書のロジックは流用）  
2. .envファイルにOPENAI\_API\_KEYを定義し、core/config.pyで読み込めるようにします。  
3. ocr\_processor.pyが、設定に応じてDummyOCRとGPT4oMiniVisionOCRを切り替えられるようにします。

**テスト:**

1. 日本語の手書き文字を含むサンプル画像を用意します。  
2. .envに有効なAPIキーを設定し、アップロード処理を実行します。  
3. Streamlitの画面に表示されるextract.jsonの内容に、手書き文字が正しく認識されたテキストが格納されていることを確認します。

**完了報告:** feature/phase-3-gpt4-integrationブランチからdevelopへプルリクエストを作成してください。

### **フェーズ 4: 後処理、信頼度評価、バリデーションルール**

**目標:** データの品質を向上させ、人間による確認が必要なものを自動で振り分ける。（**各項目で異なるルールを適用できる点が重要**）

**タスク:**

1. src/app/postprocess.pyモジュールを作成します。  
2. テキスト正規化関数を実装します。  
3. CONF\_THRESHOLD（信頼度閾値）と**バリデーションルール**機能を実装します。  
4. **重要:** rois.yamlまたはテンプレートYAML内で、各項目に\*\*個別のvalidation\_rule\*\*を定義できるようにします。これにより、"郵便番号は数字7桁"、"金額は数字のみ"といった項目ごとのルールチェックが可能になります。  
   zip\_code:  
     box: \[100, 150, 120, 50\]  
     validation\_rule: "regex:^\\\\d{7}$"  
   price:  
     box: \[100, 250, 200, 50\]  
     validation\_rule: "regex:^\[0-9,\]+$"

5. 信頼度が閾値を下回るか、バリデーションルールに違反した場合、extract.jsonの該当項目に"needs\_human": trueを追加します。

**テスト:**

1. 郵便番号のOを0と読み間違えるような画像でテストし、バリデーションルールによってneeds\_humanフラグが付くことを確認します。  
2. 信頼度が低い場合にフラグが付くことを確認します。

**完了報告:** feature/phase-4-postprocessingブランチからdevelopへプルリクエストを作成してください。

### **フェーズ 5: 帳票テンプレート機能**

**目標:** 定型帳票の処理を効率化する。

**タスク:**

1. workspace/templates/にinvoice.yaml（請求書用）などのROI定義テンプレートを配置します。  
2. StreamlitのUIに、これらのテンプレートを一覧表示するst.selectbox（ドロップダウンリスト）を設置します。  
3. 利用者は、ファイルをアップロードする際に、使用するテンプレートを選択できます。ここで選択されたYAMLファイルがROI定義として使用されます。

**テスト:**

1. 請求書のサンプル画像をアップロードし、ドロップダウンからinvoiceを選択します。  
2. invoice.yamlの定義通りにOCR処理が実行されることを確認します。

**完了報告:** feature/phase-5-templatesブランチからdevelopへプルリクエストを作成してください。

### **フェーズ 6: 人間レビューUIと修正辞書**

**目標:** Streamlit上にレビュー画面を構築し、人間が効率的に修正作業を行えるようにする。

**タスク:**

1. src/app/pages/1\_Review.pyを実装します。  
2. このページは、workspace内の全ディレクトリをスキャンし、extract.jsonに"needs\_human": trueが含まれる項目を一覧表示します。  
3. 一覧の各項目について、以下の要素を表示します:  
   * 切り出された画像 (st.image)  
   * AIの認識結果 (読み取り専用テキスト)  
   * 人間が修正するためのテキスト入力ボックス (st.text\_input)  
4. 各項目の横に「修正を保存」ボタンと「辞書に登録」チェックボックス (st.checkbox) を設置します。  
5. 「修正を保存」ボタンが押されると、extract.jsonの該当部分が更新され、needs\_humanフラグがfalseになります。  
6. 「辞書に登録」がチェックされている場合、workspace/corrections.jsonlに{"wrong": "元のテキスト", "correct": "修正後のテキスト"}の形式で追記します。この辞書は将来の精度向上に利用します。

**テスト:**

1. レビューが必要なデータを意図的に生成します。  
2. レビューページにそのデータが表示されることを確認します。  
3. テキストを修正し保存後、extract.jsonが更新されることを確認します。  
4. 辞書登録をチェックして保存後、corrections.jsonlにデータが追記されることを確認します。

**完了報告:** feature/phase-6-review-uiブランチからdevelopへプルリクエストを作成してください。

### **フェーズ 7: 自動帳票振り分け機能**

**目標:** 利用者がテンプレートを選ぶ手間を省く。

**タスク:**

1. フェーズ5で作成したテンプレート選択のst.selectboxに「自動検出」という選択肢を追加します。  
2. 「自動検出」が選ばれた場合、アップロードされた画像の全体を一度ダミーOCR（または低解像度で本OCR）にかけ、含まれるキーワード（例: "請求書", "納品書", "御中"）から最も確からしいテンプレートを自動で選択するロジックを実装します。  
3. 選択されたテンプレートを使って、以降の処理を進めます。

**テスト:**

1. キーワードが明確な請求書画像をアップロードし、「自動検出」を選択します。  
2. システムがinvoice.yamlを自動で選択し、正しく処理されることを確認します。

**完了報告:** feature/phase-7-auto-classifyブランチからdevelopへプルリクエストを作成してください。

### **フェーズ 8: パフォーマンス・ダッシュボード**

**目標:** システムの運用状況を可視化し、改善に役立てる。

**タスク:**

1. src/app/pages/2\_Dashboard.pyを実装します。  
2. このページでは、workspace内の全extract.jsonをpandasで読み込み、以下の指標を計算・表示します。  
   * 総処理ドキュメント数 (st.metric)  
   * 総処理フィールド数 (st.metric)  
   * 自動確定率（needs\_humanフラグが付かなかった割合） (st.metricとゲージ)  
   * 日別の処理枚数の推移 (st.line\_chart)  
3. 定期的にデータを再読み込みする「更新」ボタンを設置します。

**テスト:**

1. 複数のドキュメントを処理し、データが蓄積された状態にします。  
2. ダッシュボードページに、計算された指標が正しく表示されることを確認します。

**完了報告:** feature/phase-8-dashboardブランチからdevelopへプルリクエストを作成してください。
